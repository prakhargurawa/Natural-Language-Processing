{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ANLP_Lab8_Prakhar.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZbunxcIfZgk"
      },
      "source": [
        "# Objectives\n",
        "* Learn to preprocess the data for Neural Machine Translation system\n",
        "* Learn to train NMT using encoder-decoder model\n",
        "* Learn to use the trained model to create inference\n",
        "* Reference: https://keras.io \n",
        "https://github.com/keras-team/keras/blob/master/examples/lstm_seq2seq.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u66-P69TOmS9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82528f7f-2845-4c6c-be17-201c1992f3d3"
      },
      "source": [
        "import numpy as np\n",
        "import keras, tensorflow\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Dense"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shyumtBqeKVI"
      },
      "source": [
        "##**Section 1**\n",
        "\n",
        "---\n",
        "\n",
        "## **Data Preparation **"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhvOghq8OnW6"
      },
      "source": [
        "**Task 1**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "There are few datasets for langauge trasnaltion task are available from Tatoeba Project (http://www.manythings.org/anki/ ).\n",
        "\n",
        "*  Download preferred langauge pair\n",
        "*  Extract the file and upload it to colab\n",
        "*  Create a list of lines by splitting the text file at every occurance of '\\n'\n",
        "*  Print number of sentences\n",
        "*  Print 100th sentence in original script\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGJwxkrxTelg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7db9f5f4-99a8-438c-96da-3548c71b3558"
      },
      "source": [
        "!wget http://www.manythings.org/anki/nld-eng.zip\n",
        "!unzip nld-eng.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-25 09:37:31--  http://www.manythings.org/anki/nld-eng.zip\n",
            "Resolving www.manythings.org (www.manythings.org)... 172.67.173.198, 104.21.55.222, 2606:4700:3031::6815:37de, ...\n",
            "Connecting to www.manythings.org (www.manythings.org)|172.67.173.198|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1975354 (1.9M) [application/zip]\n",
            "Saving to: ‘nld-eng.zip’\n",
            "\n",
            "nld-eng.zip         100%[===================>]   1.88M  4.18MB/s    in 0.5s    \n",
            "\n",
            "2021-04-25 09:37:32 (4.18 MB/s) - ‘nld-eng.zip’ saved [1975354/1975354]\n",
            "\n",
            "Archive:  nld-eng.zip\n",
            "  inflating: _about.txt              \n",
            "  inflating: nld.txt                 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFRmNnlTOmi_"
      },
      "source": [
        "filename=\"nld.txt\"\n",
        "with open(filename , 'r') as tamil_file:\n",
        "  lines=tamil_file.read().split('\\n')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtI54EeOjJLU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ca53597-f95f-42e6-d790-36c184f31c36"
      },
      "source": [
        "print(len(lines))\n",
        "print(lines[100])\n",
        "#lines"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "54973\n",
            "Come in.\tKomt u binnen!\tCC-BY 2.0 (France) Attribution: tatoeba.org #348091 (Hertz) & #384254 (Dorenda)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RiTMo8UW83F"
      },
      "source": [
        "**Task 2**\n",
        "\n",
        "---\n",
        "\n",
        "* Split each line into input text and target text\n",
        "* Add '\\t' to denote begning of sentence and '\\n'  or '<eos\\>' to denote end of the sentence to the each target line.\n",
        "* Compute every set of character in the input text and target text\n",
        "* Print input characters and target characters as sorted list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDW2I1TrWtLc"
      },
      "source": [
        "input_texts = list()\n",
        "target_texts = list()\n",
        "input_characters = set()\n",
        "target_characters = set()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmQC0PyxXzR8"
      },
      "source": [
        "num_samples = 10000\n",
        "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
        "  #print(line)\n",
        "  input_text, target_text,_ = line.split('\\t')\n",
        "  target_text = '\\t' + target_text + '\\n'\n",
        "  input_texts.append(input_text)\n",
        "  target_texts.append(target_text)\n",
        "  for char in input_text:\n",
        "    if char not in input_characters:\n",
        "      input_characters.add(char)\n",
        "  for char in target_text:\n",
        "    if char not in target_characters:\n",
        "      target_characters.add(char)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3-iYgr7XcBu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52f31aa2-509a-447b-c107-f8b9dbaa09c7"
      },
      "source": [
        "input_characters = sorted(list(input_characters))\n",
        "target_characters = sorted(list(target_characters))\n",
        "num_encoder_tokens = len(input_characters)\n",
        "num_decoder_tokens = len(target_characters)\n",
        "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
        "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
        "\n",
        "print('Number of samples:', len(input_texts))\n",
        "print('Number of unique input tokens:', num_encoder_tokens)\n",
        "print('Number of unique output tokens:', num_decoder_tokens)\n",
        "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
        "print('Max sequence length for outputs:', max_decoder_seq_length)\n",
        "print(\"Input characters\",input_characters)\n",
        "print(\"Target characters\",target_characters)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Number of samples:', 10000)\n",
            "('Number of unique input tokens:', 69)\n",
            "('Number of unique output tokens:', 79)\n",
            "('Max sequence length for inputs:', 18)\n",
            "('Max sequence length for outputs:', 54)\n",
            "('Input characters', [' ', '!', '\"', '$', \"'\", ',', '-', '.', '0', '1', '2', '3', '4', '5', '7', '8', '9', ':', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'Y', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z'])\n",
            "('Target characters', ['\\t', '\\n', ' ', '!', '\"', '$', \"'\", ',', '-', '.', '0', '1', '2', '3', '4', '5', '7', '8', '9', ':', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'R', 'S', 'T', 'U', 'V', 'W', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '\\x80', '\\x8b', '\\xa8', '\\xa9', '\\xaa', '\\xab', '\\xaf', '\\xc3', '\\xe2'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIXRZ8AUZKVB"
      },
      "source": [
        "**Task 3**\n",
        "\n",
        "---\n",
        "\n",
        "*  Tokenize our characters by assigning each unique character to an integer value.\n",
        "*  Create one-hot encoding\n",
        "*  Create numeric data with one-hot encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXyzaZ-AZjvJ"
      },
      "source": [
        "input_token_index = dict([(char,i) for i, char in enumerate(input_characters)])\n",
        "target_token_index= dict([(char,i) for i, char in enumerate(target_characters)])"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AP5ZJ6irF6vl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "436e8563-bbe2-4636-becf-6fa9d69d7220"
      },
      "source": [
        "input_token_index"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{' ': 0,\n",
              " '!': 1,\n",
              " '\"': 2,\n",
              " '$': 3,\n",
              " \"'\": 4,\n",
              " ',': 5,\n",
              " '-': 6,\n",
              " '.': 7,\n",
              " '0': 8,\n",
              " '1': 9,\n",
              " '2': 10,\n",
              " '3': 11,\n",
              " '4': 12,\n",
              " '5': 13,\n",
              " '7': 14,\n",
              " '8': 15,\n",
              " '9': 16,\n",
              " ':': 17,\n",
              " '?': 18,\n",
              " 'A': 19,\n",
              " 'B': 20,\n",
              " 'C': 21,\n",
              " 'D': 22,\n",
              " 'E': 23,\n",
              " 'F': 24,\n",
              " 'G': 25,\n",
              " 'H': 26,\n",
              " 'I': 27,\n",
              " 'J': 28,\n",
              " 'K': 29,\n",
              " 'L': 30,\n",
              " 'M': 31,\n",
              " 'N': 32,\n",
              " 'O': 33,\n",
              " 'P': 34,\n",
              " 'Q': 35,\n",
              " 'R': 36,\n",
              " 'S': 37,\n",
              " 'T': 38,\n",
              " 'U': 39,\n",
              " 'V': 40,\n",
              " 'W': 41,\n",
              " 'Y': 42,\n",
              " 'a': 43,\n",
              " 'b': 44,\n",
              " 'c': 45,\n",
              " 'd': 46,\n",
              " 'e': 47,\n",
              " 'f': 48,\n",
              " 'g': 49,\n",
              " 'h': 50,\n",
              " 'i': 51,\n",
              " 'j': 52,\n",
              " 'k': 53,\n",
              " 'l': 54,\n",
              " 'm': 55,\n",
              " 'n': 56,\n",
              " 'o': 57,\n",
              " 'p': 58,\n",
              " 'q': 59,\n",
              " 'r': 60,\n",
              " 's': 61,\n",
              " 't': 62,\n",
              " 'u': 63,\n",
              " 'v': 64,\n",
              " 'w': 65,\n",
              " 'x': 66,\n",
              " 'y': 67,\n",
              " 'z': 68}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IUfXaToZ2Rg"
      },
      "source": [
        "The encoder_input_data will consist of  samples of the maximum sequence length (24) filled with the respective one-hot-encoded tokens (in this case a vector of length 74). The decoder_input_data and the decoder_target_data are both constructed in the same way as the input data for the encoder. We need to construct those two sequences because we're training our model through a process called teacher forcing, where the decoder learns to generate decoder_target_data[t+1...] given decoder_input_data[...t] while taking into account the input sequence via the encoder's internal state. Therefore we have to offset decoder_target_data by one timestep."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBY5c-6pZsry"
      },
      "source": [
        "encoder_input_data=np.zeros((len(input_texts),max_encoder_seq_length,num_encoder_tokens),dtype='float32')\n",
        "decoder_input_data=np.zeros((len(input_texts), max_decoder_seq_length, num_decoder_tokens),dtype='float32')\n",
        "decoder_target_data=np.zeros((len(input_texts), max_decoder_seq_length, num_decoder_tokens),dtype='float32')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sx0TDwf0ZueF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76b2dd9f-ad9a-45d4-bd30-907cda161ee7"
      },
      "source": [
        "print(encoder_input_data.shape)\n",
        "print(decoder_input_data.shape)\n",
        "print(decoder_target_data.shape)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 18, 69)\n",
            "(10000, 54, 79)\n",
            "(10000, 54, 79)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8E3LkfJbYVF"
      },
      "source": [
        "for i, (input_text,target_text) in enumerate(zip(input_texts,target_texts)):\n",
        "  for t, char in enumerate(input_text):\n",
        "    encoder_input_data[i,t,input_token_index[char]]=1\n",
        "    \n",
        "  for t, char in enumerate(target_text):\n",
        "    decoder_input_data[i,t,target_token_index[char]]=1\n",
        "    if t>0:\n",
        "      decoder_target_data[i,t-1,target_token_index[char]]=1"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8bTOqHfeCHZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15d538f4-c7b3-4fe8-f835-0c9308abf602"
      },
      "source": [
        "print(encoder_input_data[0][0])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbGU3H0gecBd"
      },
      "source": [
        "## **Section 2**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "## **Building the Model **"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5vkd552e6ck"
      },
      "source": [
        "**Hyperparameters **"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lz-weK3JuXmy"
      },
      "source": [
        "** Use GPU/TPU to run the model **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5F3cPK2eE1Z"
      },
      "source": [
        "batch_size=64\n",
        "epochs= 2\n",
        "latent_dim =256 # latent dimensionality of the encoding space"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rq6r-IufHWr"
      },
      "source": [
        "encoder_inputs=Input(shape=(None,num_encoder_tokens))\n",
        "encoder_lstm= LSTM(latent_dim,return_state=True) #\n",
        "encoder_outputs,state_h,state_c= encoder_lstm(encoder_inputs)\n",
        "encoder_states= [state_h,state_c]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dL70cqDogeDh"
      },
      "source": [
        "decoder_inputs=Input(shape=(None,num_decoder_tokens))\n",
        "decoder_lstm=LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_output,_,_=decoder_lstm(decoder_inputs,initial_state=encoder_states)\n",
        "\n",
        "decoder_dense= Dense(num_decoder_tokens, activation='softmax')\n",
        "decoder_outputs=decoder_dense(decoder_output)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0Pun-T4hM6b"
      },
      "source": [
        "model= Model(inputs=[encoder_inputs,decoder_inputs],outputs=decoder_outputs)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqwcU36sh4ld",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fe06bcc-fbab-4bbe-e6e7-49af3b356b5f"
      },
      "source": [
        "model.compile(optimizer='rmsprop',loss='categorical_crossentropy')\n",
        "model.summary()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, None, 69)     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            (None, None, 79)     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, 256), (None, 333824      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   [(None, None, 256),  344064      input_2[0][0]                    \n",
            "                                                                 lstm_1[0][1]                     \n",
            "                                                                 lstm_1[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, None, 79)     20303       lstm_2[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 698,191\n",
            "Trainable params: 698,191\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggo3qyIxh7M8"
      },
      "source": [
        "## ** Section 3 **\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "** Training Model **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPvWdhaBiBPL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78d1e60a-6710-4ba0-947d-81f08c5a12d2"
      },
      "source": [
        "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          validation_split=0.2)\n",
        "model.save('seq2seq_eng-nl.h5')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 8000 samples, validate on 2000 samples\n",
            "Epoch 1/2\n",
            "8000/8000 [==============================] - 9s 1ms/step - loss: 0.9400 - val_loss: 0.9946\n",
            "Epoch 2/2\n",
            "8000/8000 [==============================] - 7s 907us/step - loss: 0.7424 - val_loss: 0.8282\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-J_veVXaUiyQ"
      },
      "source": [
        "# Testing Machine Translation\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "* Use the compiled model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOVU0W56izum"
      },
      "source": [
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
        "model.load_weights('seq2seq_eng-nl.h5')"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M01ZBtVhUhhI"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmz0UQyFUQaN"
      },
      "source": [
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(\n",
        "  decoder_inputs, initial_state=decoder_states_inputs)\n",
        "decoder_states = [state_h, state_c]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "decoder_model = Model(\n",
        "  [decoder_inputs] + decoder_states_inputs,\n",
        "  [decoder_outputs] + decoder_states)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQXF1Si6VMKz"
      },
      "source": [
        "# reverse-lookup token index to turn sequences back to characters\n",
        "reverse_input_char_index = dict(\n",
        "  (i, char) for char, i in input_token_index.items())\n",
        "reverse_target_char_index = dict(\n",
        "  (i, char) for char, i in target_token_index.items())"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7qik3jTVR_r"
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "  # encode the input sequence to get the internal state vectors.\n",
        "  states_value = encoder_model.predict(input_seq)\n",
        "  \n",
        "  # generate empty target sequence of length 1 with only the start character\n",
        "  target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "  target_seq[0, 0, target_token_index['\\t']] = 1.\n",
        "  \n",
        "  # output sequence loop\n",
        "  stop_condition = False\n",
        "  decoded_sentence = ''\n",
        "  while not stop_condition:\n",
        "    output_tokens, h, c = decoder_model.predict(\n",
        "      [target_seq] + states_value)\n",
        "    \n",
        "    # sample a token and add the corresponding character to the \n",
        "    # decoded sequence\n",
        "    sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "    sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "    decoded_sentence += sampled_char\n",
        "    \n",
        "    # check for the exit condition: either hitting max length\n",
        "    # or predicting the 'stop' character\n",
        "    if (sampled_char == '\\n' or \n",
        "        len(decoded_sentence) > max_decoder_seq_length):\n",
        "      stop_condition = True\n",
        "      \n",
        "    # update the target sequence (length 1).\n",
        "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "    target_seq[0, 0, sampled_token_index] = 1.\n",
        "    \n",
        "    # update states\n",
        "    states_value = [h, c]\n",
        "    \n",
        "  return decoded_sentence"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iniHlKvQDbw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ae15a2c-804b-4e78-a111-d4060fd7d22e"
      },
      "source": [
        "for seq_index in range(10):\n",
        "  input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
        "  decoded_sentence = decode_sequence(input_seq)\n",
        "  print('-')\n",
        "  print('Input sentence:', input_texts[seq_index])\n",
        "  print('Decoded sentence:', decoded_sentence)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-\n",
            "('Input sentence:', 'Go.')\n",
            "('Decoded sentence:', 'Hen het het geet.\\n')\n",
            "-\n",
            "('Input sentence:', 'Go.')\n",
            "('Decoded sentence:', 'Hen het het geet.\\n')\n",
            "-\n",
            "('Input sentence:', 'Hi.')\n",
            "('Decoded sentence:', 'aat het het geet.\\n')\n",
            "-\n",
            "('Input sentence:', 'Hi.')\n",
            "('Decoded sentence:', 'aat het het geet.\\n')\n",
            "-\n",
            "('Input sentence:', 'Hi.')\n",
            "('Decoded sentence:', 'aat het het geet.\\n')\n",
            "-\n",
            "('Input sentence:', 'Run!')\n",
            "('Decoded sentence:', 'Hen het het geet.\\n')\n",
            "-\n",
            "('Input sentence:', 'Run!')\n",
            "('Decoded sentence:', 'Hen het het geet.\\n')\n",
            "-\n",
            "('Input sentence:', 'Run.')\n",
            "('Decoded sentence:', 'Hen het het geet.\\n')\n",
            "-\n",
            "('Input sentence:', 'Run.')\n",
            "('Decoded sentence:', 'Hen het het geet.\\n')\n",
            "-\n",
            "('Input sentence:', 'Who?')\n",
            "('Decoded sentence:', 'He het het het geen.\\n')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBJ4SIpAQHP_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}