{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ANLP_Lab_6_Prakhar.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9mdQ-SsBTpG"
      },
      "source": [
        "import math\n",
        "import numpy\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fZQYzTjBYkr"
      },
      "source": [
        "# Input: english sentence e, foreign sentence f, hash of translation probabilities t, epsilon \n",
        "# Output: probability of e given f\n",
        "\n",
        "def probability_e_f(e, f, t, epsilon=1):\n",
        "    l_e = len(e)\n",
        "    l_f = len(f)\n",
        "    p_e_f = 1\n",
        "    \n",
        "    for ew in e: # iterate over english words ew in english sentence e\n",
        "        inner_sum = 0\n",
        "        for fw in f: # iterate over foreign words fw in foreign sentence f\n",
        "            inner_sum += t[(ew, fw)]\n",
        "        p_e_f = inner_sum * p_e_f\n",
        "    \n",
        "    p_e_f = p_e_f * epsilon / (l_f**l_e)\n",
        "    \n",
        "    return p_e_f   "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23PuoEVWBcnn"
      },
      "source": [
        "# Input: Collection of sentence pairs sentence_pairs, hash of translation probabilities t, epsilon\n",
        "# Output: Perplexity of model\n",
        "\n",
        "def perplexity(sentence_pairs, t, epsilon=1, debug_output=False):\n",
        "    pp = 0\n",
        "    \n",
        "    for sp in sentence_pairs:\n",
        "        prob = probability_e_f(sp[1], sp[0], t)\n",
        "        if debug_output:\n",
        "            print('english sentence:', sp[1], 'foreign sentence:', sp[0])\n",
        "            print(prob)\n",
        "            print()\n",
        "        pp += math.log(prob, 2) # log base 2\n",
        "        \n",
        "    pp = 2.0**(-pp)\n",
        "    return pp"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pozc1x__BfMu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bbe5b8b-9d98-4d8f-e26b-ae358ea0390e"
      },
      "source": [
        "# Get sentence pairs for toy experiment\n",
        "sentence_pairs = [ \n",
        "    [ ['das', 'Haus'], ['the', 'house'] ], \n",
        "    [ ['das', 'Buch'], ['the', 'book'] ], \n",
        "    [ ['ein', 'Buch'], ['a', 'book'] ]\n",
        "]\n",
        "\n",
        "print('No. of sentences in translation memory: ', len(sentence_pairs))\n",
        "print('Content: ', sentence_pairs)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No. of sentences in translation memory:  3\n",
            "Content:  [[['das', 'Haus'], ['the', 'house']], [['das', 'Buch'], ['the', 'book']], [['ein', 'Buch'], ['a', 'book']]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "neSK4di4BiIU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fe17322-646e-45b2-be0e-2c1d39f09c01"
      },
      "source": [
        "# Extract foreign and english vocabularies\n",
        "foreign_words = []\n",
        "english_words = []\n",
        "\n",
        "for sp in sentence_pairs:\n",
        "    for ew in sp[1]: \n",
        "        english_words.append(ew)\n",
        "    for fw in sp[0]: \n",
        "        foreign_words.append(fw)\n",
        "        \n",
        "english_words = sorted(list(set(english_words)), key=lambda s: s.lower()) \n",
        "foreign_words = sorted(list(set(foreign_words)), key=lambda s: s.lower())\n",
        "print('English vocab: ', english_words)\n",
        "print('Foreign vocab: ', foreign_words)\n",
        "\n",
        "english_vocab_size = len(english_words)\n",
        "foreign_vocab_size = len(foreign_words)\n",
        "print('english_vocab_size: ', english_vocab_size)\n",
        "print('foreign_vocab_size: ', foreign_vocab_size)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "English vocab:  ['a', 'book', 'house', 'the']\n",
            "Foreign vocab:  ['Buch', 'das', 'ein', 'Haus']\n",
            "english_vocab_size:  4\n",
            "foreign_vocab_size:  4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47_N0ICnBlIb"
      },
      "source": [
        "# Routine to uniformly initialize word translation probabilities in t hash\n",
        "\n",
        "def init_prob(t, init_val, english_words, foreign_words):\n",
        "    for fw in foreign_words:\n",
        "        for ew in english_words:\n",
        "            tup = (ew, fw) # tuple required because dict key cannot be list\n",
        "            t[tup] = init_val"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzWtYVlUBrLn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18a6e444-242b-4efd-caa5-84d10d2766d9"
      },
      "source": [
        "# Main routine\n",
        "num_iterations = 5\n",
        "perplex = []\n",
        "debug_output = True\n",
        "s_total = {}\n",
        "\n",
        "# Initialize probabilities uniformly\n",
        "t = {}\n",
        "init_val = 1.0 / foreign_vocab_size\n",
        "init_prob(t, init_val, english_words, foreign_words)\n",
        "if debug_output:\n",
        "    print('Hash initialized')\n",
        "    print('No. of foreign/english pairs: ', len(t))\n",
        "    print('Content: ', t)\n",
        "    print('**************')\n",
        "    print()\n",
        "\n",
        "# Loop while not converged\n",
        "for iter in range(num_iterations):\n",
        "    \n",
        "    # Calculate perplexity\n",
        "    pp = perplexity(sentence_pairs, t, 1, True)\n",
        "    print(pp)\n",
        "    print('**************')\n",
        "    perplex.append(pp)\n",
        "\n",
        "    # Initialize\n",
        "    count = {}\n",
        "    total = {}\n",
        "\n",
        "    for fw in foreign_words:\n",
        "        total[fw] = 0.0\n",
        "        for ew in english_words:\n",
        "            count[(ew, fw)] = 0.0\n",
        "\n",
        "    for sp in sentence_pairs:\n",
        "\n",
        "        # Compute normalization\n",
        "        for ew in sp[1]:\n",
        "            s_total[ew] = 0.0\n",
        "            for fw in sp[0]:\n",
        "                s_total[ew] += t[(ew, fw)]\n",
        "\n",
        "        # Collect counts\n",
        "        for ew in sp[1]:\n",
        "            for fw in sp[0]:\n",
        "                count[(ew, fw)] += t[(ew, fw)] / s_total[ew]\n",
        "                total[fw] += t[(ew, fw)] / s_total[ew]\n",
        "\n",
        "    # Estimate probabilities\n",
        "    for fw in foreign_words:\n",
        "        for ew in english_words:\n",
        "            t[(ew, fw)] = count[(ew, fw)] / total[fw]\n",
        "\n",
        "    if debug_output:\n",
        "        print(\"--> *** t[('the','das')]\", t[('the','das')])\n",
        "        print(\"--> *** t[('book','das')]\", t[('book','das')])\n",
        "    \n",
        "        print(\"--> t[('house','das')]\", t[('house','das')])\n",
        "        print(\"--> *** t[('the','Buch')]\", t[('the','Buch')])\n",
        "        print(\"--> *** t[('book','Buch')]\", t[('book','Buch')])\n",
        "        print(\"--> t[('a','Buch')]\", t[('a','Buch')])\n",
        "        print(\"--> t[('book','ein')]\", t[('book','ein')])\n",
        "        print(\"--> t[('a','ein')]\", t[('a','ein')])\n",
        "\n",
        "        print(\"--> t[('the','Haus')]\", t[('the','Haus')])\n",
        "        print(\"--> t[('house','Haus')]\", t[('house','Haus')])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hash initialized\n",
            "No. of foreign/english pairs:  16\n",
            "Content:  {('a', 'Buch'): 0.25, ('book', 'Buch'): 0.25, ('house', 'Buch'): 0.25, ('the', 'Buch'): 0.25, ('a', 'das'): 0.25, ('book', 'das'): 0.25, ('house', 'das'): 0.25, ('the', 'das'): 0.25, ('a', 'ein'): 0.25, ('book', 'ein'): 0.25, ('house', 'ein'): 0.25, ('the', 'ein'): 0.25, ('a', 'Haus'): 0.25, ('book', 'Haus'): 0.25, ('house', 'Haus'): 0.25, ('the', 'Haus'): 0.25}\n",
            "**************\n",
            "\n",
            "english sentence: ['the', 'house'] foreign sentence: ['das', 'Haus']\n",
            "0.0625\n",
            "\n",
            "english sentence: ['the', 'book'] foreign sentence: ['das', 'Buch']\n",
            "0.0625\n",
            "\n",
            "english sentence: ['a', 'book'] foreign sentence: ['ein', 'Buch']\n",
            "0.0625\n",
            "\n",
            "4096.0\n",
            "**************\n",
            "--> *** t[('the','das')] 0.5\n",
            "--> *** t[('book','das')] 0.25\n",
            "--> t[('house','das')] 0.25\n",
            "--> *** t[('the','Buch')] 0.25\n",
            "--> *** t[('book','Buch')] 0.5\n",
            "--> t[('a','Buch')] 0.25\n",
            "--> t[('book','ein')] 0.5\n",
            "--> t[('a','ein')] 0.5\n",
            "--> t[('the','Haus')] 0.5\n",
            "--> t[('house','Haus')] 0.5\n",
            "english sentence: ['the', 'house'] foreign sentence: ['das', 'Haus']\n",
            "0.1875\n",
            "\n",
            "english sentence: ['the', 'book'] foreign sentence: ['das', 'Buch']\n",
            "0.140625\n",
            "\n",
            "english sentence: ['a', 'book'] foreign sentence: ['ein', 'Buch']\n",
            "0.1875\n",
            "\n",
            "202.27160493827165\n",
            "**************\n",
            "--> *** t[('the','das')] 0.6363636363636364\n",
            "--> *** t[('book','das')] 0.18181818181818182\n",
            "--> t[('house','das')] 0.18181818181818182\n",
            "--> *** t[('the','Buch')] 0.18181818181818182\n",
            "--> *** t[('book','Buch')] 0.6363636363636364\n",
            "--> t[('a','Buch')] 0.18181818181818182\n",
            "--> t[('book','ein')] 0.4285714285714286\n",
            "--> t[('a','ein')] 0.5714285714285715\n",
            "--> t[('the','Haus')] 0.4285714285714286\n",
            "--> t[('house','Haus')] 0.5714285714285715\n",
            "english sentence: ['the', 'house'] foreign sentence: ['das', 'Haus']\n",
            "0.20053972002023954\n",
            "\n",
            "english sentence: ['the', 'book'] foreign sentence: ['das', 'Buch']\n",
            "0.16735537190082642\n",
            "\n",
            "english sentence: ['a', 'book'] foreign sentence: ['ein', 'Buch']\n",
            "0.20053972002023954\n",
            "\n",
            "148.57971953377827\n",
            "**************\n",
            "--> *** t[('the','das')] 0.7478974515333995\n",
            "--> *** t[('book','das')] 0.1208425438930813\n",
            "--> t[('house','das')] 0.13126000457351933\n",
            "--> *** t[('the','Buch')] 0.1208425438930813\n",
            "--> *** t[('book','Buch')] 0.7478974515333995\n",
            "--> t[('a','Buch')] 0.13126000457351933\n",
            "--> t[('book','ein')] 0.34661354581673304\n",
            "--> t[('a','ein')] 0.6533864541832669\n",
            "--> t[('the','Haus')] 0.34661354581673304\n",
            "--> t[('house','Haus')] 0.6533864541832669\n",
            "english sentence: ['the', 'house'] foreign sentence: ['das', 'Haus']\n",
            "0.21470104453528496\n",
            "\n",
            "english sentence: ['the', 'book'] foreign sentence: ['das', 'Buch']\n",
            "0.18867729491340043\n",
            "\n",
            "english sentence: ['a', 'book'] foreign sentence: ['ein', 'Buch']\n",
            "0.21470104453528496\n",
            "\n",
            "114.97728367667098\n",
            "**************\n",
            "--> *** t[('the','das')] 0.8344395715124338\n",
            "--> *** t[('book','das')] 0.07516523179034365\n",
            "--> t[('house','das')] 0.09039519669722251\n",
            "--> *** t[('the','Buch')] 0.07516523179034365\n",
            "--> *** t[('book','Buch')] 0.8344395715124339\n",
            "--> t[('a','Buch')] 0.09039519669722253\n",
            "--> t[('book','ein')] 0.2755211789521138\n",
            "--> t[('a','ein')] 0.7244788210478862\n",
            "--> t[('the','Haus')] 0.2755211789521138\n",
            "--> t[('house','Haus')] 0.7244788210478862\n",
            "english sentence: ['the', 'house'] foreign sentence: ['das', 'Haus']\n",
            "0.22611954406760545\n",
            "\n",
            "english sentence: ['the', 'book'] foreign sentence: ['das', 'Buch']\n",
            "0.2068452245478711\n",
            "\n",
            "english sentence: ['a', 'book'] foreign sentence: ['ein', 'Buch']\n",
            "0.2261195440676055\n",
            "\n",
            "94.55365015392323\n",
            "**************\n",
            "--> *** t[('the','das')] 0.8960831177730378\n",
            "--> *** t[('book','das')] 0.04436291470681886\n",
            "--> t[('house','das')] 0.05955396752014332\n",
            "--> *** t[('the','Buch')] 0.044362914706818864\n",
            "--> *** t[('book','Buch')] 0.8960831177730377\n",
            "--> t[('a','Buch')] 0.059553967520143324\n",
            "--> t[('book','ein')] 0.21826012818351037\n",
            "--> t[('a','ein')] 0.7817398718164896\n",
            "--> t[('the','Haus')] 0.21826012818351043\n",
            "--> t[('house','Haus')] 0.7817398718164896\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}