{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab_3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wxp5NGIC6Sz"
      },
      "source": [
        "# Advanced NLP - Lab 3\n",
        "\n",
        "In this lab, we are going to do some simple text classification using deep neural networks. We are going to use the `imdb` dataset that comes with Keras. The description of this dataset according to Keras's documentation is \n",
        "\n",
        "> This is a dataset of 25,000 movies reviews from IMDB, labeled by sentiment (positive/negative). Reviews have been preprocessed, and each review is encoded as a list of word indexes (integers). For convenience, words are indexed by overall frequency in the dataset, so that for instance the integer \"3\" encodes the 3rd most frequent word in the data. This allows for quick filtering operations such as: \"only consider the top 10,000 most common words, but eliminate the top 20 most common words\".\n",
        "\n",
        "https://keras.io/api/datasets/imdb/\n",
        "\n",
        "We will start by loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnPk5qPuBYZX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d29e2f2c-7226-4eae-f7cb-284ab056cdac"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import imdb\n",
        "\n",
        "train, test = imdb.load_data()\n",
        "train"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 22665, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 21631, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 31050, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]),\n",
              "        list([1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 10156, 4, 1153, 9, 194, 775, 7, 8255, 11596, 349, 2637, 148, 605, 15358, 8003, 15, 123, 125, 68, 23141, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 36893, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 25249, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 46151, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]),\n",
              "        list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 5974, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 44076, 780, 8, 106, 14, 6905, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 51428, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113]),\n",
              "        ...,\n",
              "        list([1, 11, 6, 230, 245, 6401, 9, 6, 1225, 446, 86527, 45, 2174, 84, 8322, 4007, 21, 4, 912, 84, 14532, 325, 725, 134, 15271, 1715, 84, 5, 36, 28, 57, 1099, 21, 8, 140, 8, 703, 5, 11656, 84, 56, 18, 1644, 14, 9, 31, 7, 4, 9406, 1209, 2295, 26094, 1008, 18, 6, 20, 207, 110, 563, 12, 8, 2901, 17793, 8, 97, 6, 20, 53, 4767, 74, 4, 460, 364, 1273, 29, 270, 11, 960, 108, 45, 40, 29, 2961, 395, 11, 6, 4065, 500, 7, 14492, 89, 364, 70, 29, 140, 4, 64, 4780, 11, 4, 2678, 26, 178, 4, 529, 443, 17793, 5, 27, 710, 117, 74936, 8123, 165, 47, 84, 37, 131, 818, 14, 595, 10, 10, 61, 1242, 1209, 10, 10, 288, 2260, 1702, 34, 2901, 17793, 4, 65, 496, 4, 231, 7, 790, 5, 6, 320, 234, 2766, 234, 1119, 1574, 7, 496, 4, 139, 929, 2901, 17793, 7750, 5, 4241, 18, 4, 8497, 13164, 250, 11, 1818, 7561, 4, 4217, 5408, 747, 1115, 372, 1890, 1006, 541, 9303, 7, 4, 59, 11027, 4, 3586, 22459]),\n",
              "        list([1, 1446, 7079, 69, 72, 3305, 13, 610, 930, 8, 12, 582, 23, 5, 16, 484, 685, 54, 349, 11, 4120, 2959, 45, 58, 1466, 13, 197, 12, 16, 43, 23, 21469, 5, 62, 30, 145, 402, 11, 4131, 51, 575, 32, 61, 369, 71, 66, 770, 12, 1054, 75, 100, 2198, 8, 4, 105, 37, 69, 147, 712, 75, 3543, 44, 257, 390, 5, 69, 263, 514, 105, 50, 286, 1814, 23, 4, 123, 13, 161, 40, 5, 421, 4, 116, 16, 897, 13, 40691, 40, 319, 5872, 112, 6700, 11, 4803, 121, 25, 70, 3468, 4, 719, 3798, 13, 18, 31, 62, 40, 8, 7200, 4, 29455, 7, 14, 123, 5, 942, 25, 8, 721, 12, 145, 5, 202, 12, 160, 580, 202, 12, 6, 52, 58, 11418, 92, 401, 728, 12, 39, 14, 251, 8, 15, 251, 5, 21213, 12, 38, 84, 80, 124, 12, 9, 23]),\n",
              "        list([1, 17, 6, 194, 337, 7, 4, 204, 22, 45, 254, 8, 106, 14, 123, 4, 12815, 270, 14437, 5, 16923, 12255, 732, 2098, 101, 405, 39, 14, 1034, 4, 1310, 9, 115, 50, 305, 12, 47, 4, 168, 5, 235, 7, 38, 111, 699, 102, 7, 4, 4039, 9245, 9, 24, 6, 78, 1099, 17, 2345, 16553, 21, 27, 9685, 6139, 5, 29043, 1603, 92, 1183, 4, 1310, 7, 4, 204, 42, 97, 90, 35, 221, 109, 29, 127, 27, 118, 8, 97, 12, 157, 21, 6789, 85010, 9, 6, 66, 78, 1099, 4, 631, 1191, 5, 2642, 272, 191, 1070, 6, 7585, 8, 2197, 70907, 10755, 544, 5, 383, 1271, 848, 1468, 12183, 497, 16876, 8, 1597, 8778, 19280, 21, 60, 27, 239, 9, 43, 8368, 209, 405, 10, 10, 12, 764, 40, 4, 248, 20, 12, 16, 5, 174, 1791, 72, 7, 51, 6, 1739, 22, 4, 204, 131, 9])],\n",
              "       dtype=object), array([1, 0, 0, ..., 0, 1, 0]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpW-rPzTDiMS"
      },
      "source": [
        "## Question 1\n",
        "\n",
        "Convert each document into a 1-of-V vector containing the frequency of each of the top 1,000 words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Z2pSAcdCYIA"
      },
      "source": [
        "from collections import Counter\n",
        "import numpy as np\n",
        "\n",
        "def to_freq(v):\n",
        "  \"Your code goes here\"\n",
        "  f=Counter(v)\n",
        "  return np.array([f[x] for x in range(1,1001)])\n",
        "  \n",
        "X = np.array([to_freq(v) for v in train[0]])\n",
        "y = np.array(train[1])\n",
        "\"Try to create same for test dataset\"\n",
        "X_test = np.array([to_freq(v) for v in test[0]])\n",
        "y_test = np.array(test[1])"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UOqxwtarS0I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7298c62-e216-4637-c779-689c72b7cbff"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 1000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50UebubDj-gE"
      },
      "source": [
        "## Question 2\n",
        "\n",
        "Now build a simple classifier on this to predict the sentiment of the reviews using Keras. You can run this experiment with 100 datasets from train set. Try with two different sets :- One with Softmax and one with Sigmoid actiavtion function and check the accuracy difference."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNYXL85DVaFb",
        "outputId": "2b74e469-182b-476a-d470-5bf238fbfd88"
      },
      "source": [
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense\r\n",
        "import tensorflow.compat.v1 as tf\r\n",
        "import keras\r\n",
        "import keras.utils\r\n",
        "\r\n",
        "model = Sequential()\r\n",
        "model.add(Dense(1, activation='softmax', input_dim=1000))\r\n",
        "model.compile(loss='binary_crossentropy',\r\n",
        "              optimizer='adam',\r\n",
        "              metrics=['accuracy'])\r\n",
        "model.fit(X, y, batch_size=128, epochs=6)\r\n",
        "score = model.evaluate(X_test, y_test)\r\n",
        "print(\"Test Accuracy:\", score[1])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/6\n",
            "196/196 [==============================] - 1s 1ms/step - loss: 0.6362 - accuracy: 0.4999\n",
            "Epoch 2/6\n",
            "196/196 [==============================] - 0s 2ms/step - loss: 0.4419 - accuracy: 0.4960\n",
            "Epoch 3/6\n",
            "196/196 [==============================] - 0s 2ms/step - loss: 0.3921 - accuracy: 0.4952\n",
            "Epoch 4/6\n",
            "196/196 [==============================] - 0s 2ms/step - loss: 0.3597 - accuracy: 0.5023\n",
            "Epoch 5/6\n",
            "196/196 [==============================] - 0s 2ms/step - loss: 0.3443 - accuracy: 0.4997\n",
            "Epoch 6/6\n",
            "196/196 [==============================] - 0s 2ms/step - loss: 0.3281 - accuracy: 0.4998\n",
            "782/782 [==============================] - 1s 859us/step - loss: 0.3430 - accuracy: 0.5000\n",
            "Test Accuracy: 0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jh7EUpPGktEe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "302260dd-a0ef-498f-b6ef-21bd814ad5f4"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import tensorflow.compat.v1 as tf\n",
        "import keras\n",
        "import keras.utils\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(1, activation='sigmoid', input_dim=1000))\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "model.fit(X, y, batch_size=128, epochs=6)\n",
        "score = model.evaluate(X_test, y_test)\n",
        "print(\"Test Accuracy:\", score[1])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/6\n",
            "196/196 [==============================] - 1s 2ms/step - loss: 0.6430 - accuracy: 0.6319\n",
            "Epoch 2/6\n",
            "196/196 [==============================] - 0s 2ms/step - loss: 0.4396 - accuracy: 0.8275\n",
            "Epoch 3/6\n",
            "196/196 [==============================] - 0s 2ms/step - loss: 0.3848 - accuracy: 0.8562\n",
            "Epoch 4/6\n",
            "196/196 [==============================] - 0s 2ms/step - loss: 0.3554 - accuracy: 0.8651\n",
            "Epoch 5/6\n",
            "196/196 [==============================] - 0s 2ms/step - loss: 0.3421 - accuracy: 0.8691\n",
            "Epoch 6/6\n",
            "196/196 [==============================] - 0s 2ms/step - loss: 0.3289 - accuracy: 0.8748\n",
            "782/782 [==============================] - 1s 854us/step - loss: 0.3379 - accuracy: 0.8652\n",
            "Test Accuracy: 0.8652399778366089\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gf0Hc0TJmCYA"
      },
      "source": [
        "Look at the Keras documentation and add a dense layer with a dimensionality of 20 with a ReLU activation to your model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gggk-21pmSW-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a8696de-bd03-4bff-cee2-7301d7c4f6e0"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import tensorflow.compat.v1 as tf\n",
        "import keras\n",
        "import keras.utils\n",
        "\n",
        "model = Sequential()\n",
        "\"Your code goes here\"\n",
        "model.add(Dense(20, activation='relu', input_dim=1000))\n",
        "model.add(Dense(1, activation='sigmoid', input_dim=20))\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "model.fit(X, y, batch_size=128, epochs=6)\n",
        "score = model.evaluate(X_test, y_test)\n",
        "print(\"Test Accuracy:\", score[1])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/6\n",
            "196/196 [==============================] - 1s 2ms/step - loss: 0.5232 - accuracy: 0.7398\n",
            "Epoch 2/6\n",
            "196/196 [==============================] - 1s 3ms/step - loss: 0.3268 - accuracy: 0.8689\n",
            "Epoch 3/6\n",
            "196/196 [==============================] - 0s 2ms/step - loss: 0.3146 - accuracy: 0.8706\n",
            "Epoch 4/6\n",
            "196/196 [==============================] - 1s 3ms/step - loss: 0.3055 - accuracy: 0.8790\n",
            "Epoch 5/6\n",
            "196/196 [==============================] - 0s 2ms/step - loss: 0.2941 - accuracy: 0.8799\n",
            "Epoch 6/6\n",
            "196/196 [==============================] - 1s 3ms/step - loss: 0.2970 - accuracy: 0.8783\n",
            "782/782 [==============================] - 1s 1ms/step - loss: 0.3288 - accuracy: 0.8646\n",
            "Test Accuracy: 0.8646399974822998\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzhBNSc7m3MN"
      },
      "source": [
        "## Question 3\n",
        "\n",
        "Look at the documentation for building and training a model\n",
        "\n",
        "https://keras.io/guides/training_with_built_in_methods/\n",
        "\n",
        "How would you go about evaluating your model? Hint : Try built in function of Keras Model class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_610Vb9RnWGu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2b2a31e-59e3-4256-d74d-397f82854c1f"
      },
      "source": [
        "\"Your code goes here\"\r\n",
        "score = model.evaluate(X_test, y_test)\r\n",
        "print(\"Test Accuracy:\", score[1])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "782/782 [==============================] - 1s 991us/step - loss: 0.3288 - accuracy: 0.8646\n",
            "Test Accuracy: 0.8646399974822998\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHtwZQTFnyOg"
      },
      "source": [
        "## Question 4\n",
        "\n",
        "Use the [Keras documentation search](https://keras.io/search.html) make the following modifications to your code:\n",
        "\n",
        "* Add a dropout layer\n",
        "* Change the optimizer to AdaGrad\n",
        "* Change the learning rate of the Adam optimizer\n",
        "* Add L2 regularization to the output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NYMRNCiokW1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0156a665-c6f7-4a99-e410-de8219c87b80"
      },
      "source": [
        "from keras.layers import Dropout\n",
        "from keras.optimizers import Adam,Adagrad\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(20, activation='relu', input_dim=1000,kernel_regularizer='l2'))\n",
        "model.add(Dropout(0.2,input_shape=(1000,)))\n",
        "model.add(Dense(1, activation='sigmoid', input_dim=20,kernel_regularizer='l2'))\n",
        "opt = keras.optimizers.Adagrad(learning_rate=0.001)\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "model.fit(X, y, batch_size=128, epochs=6)\n",
        "score = model.evaluate(X_test, y_test)\n",
        "print(\"Test Accuracy:\", score[1])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/6\n",
            "196/196 [==============================] - 1s 2ms/step - loss: 1.1997 - accuracy: 0.5403\n",
            "Epoch 2/6\n",
            "196/196 [==============================] - 1s 3ms/step - loss: 1.0750 - accuracy: 0.5878\n",
            "Epoch 3/6\n",
            "196/196 [==============================] - 0s 3ms/step - loss: 1.0515 - accuracy: 0.6090\n",
            "Epoch 4/6\n",
            "196/196 [==============================] - 1s 3ms/step - loss: 1.0276 - accuracy: 0.6345\n",
            "Epoch 5/6\n",
            "196/196 [==============================] - 0s 3ms/step - loss: 1.0154 - accuracy: 0.6442\n",
            "Epoch 6/6\n",
            "196/196 [==============================] - 0s 2ms/step - loss: 0.9973 - accuracy: 0.6462\n",
            "782/782 [==============================] - 1s 1ms/step - loss: 0.9792 - accuracy: 0.6820\n",
            "Test Accuracy: 0.6819599866867065\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arMKAbjxocWl"
      },
      "source": [
        "## Question 5\n",
        "\n",
        "Experiment and find a setting that improves the test accuracy. What works best?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgqQtQmxojnz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23ef1783-95d2-4362-a66d-181b0f54b536"
      },
      "source": [
        "from keras.optimizers import RMSprop\r\n",
        "\r\n",
        "model = Sequential()\r\n",
        "model.add(Dense(20, activation='relu', input_dim=1000,kernel_regularizer='l2'))\r\n",
        "model.add(Dropout(0.2,input_shape=(1000,)))\r\n",
        "#model.add(Dense(20, activation='relu', input_dim=20,kernel_regularizer='l2'))\r\n",
        "model.add(Dense(1, activation='sigmoid', input_dim=20,kernel_regularizer='l2'))\r\n",
        "\r\n",
        "opt = RMSprop(lr=0.0001, decay=1e-6)\r\n",
        "model.compile(loss='binary_crossentropy',\r\n",
        "              optimizer=opt,\r\n",
        "              metrics=['accuracy'])\r\n",
        "model.fit(X, y, batch_size=128, epochs=6)\r\n",
        "score = model.evaluate(X_test, y_test)\r\n",
        "print(\"Test Accuracy:\", score[1])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/6\n",
            "196/196 [==============================] - 1s 3ms/step - loss: 1.1645 - accuracy: 0.5560\n",
            "Epoch 2/6\n",
            "196/196 [==============================] - 0s 3ms/step - loss: 0.8841 - accuracy: 0.6858\n",
            "Epoch 3/6\n",
            "196/196 [==============================] - 1s 3ms/step - loss: 0.7469 - accuracy: 0.7523\n",
            "Epoch 4/6\n",
            "196/196 [==============================] - 0s 3ms/step - loss: 0.6689 - accuracy: 0.7857\n",
            "Epoch 5/6\n",
            "196/196 [==============================] - 1s 3ms/step - loss: 0.6168 - accuracy: 0.8065\n",
            "Epoch 6/6\n",
            "196/196 [==============================] - 1s 3ms/step - loss: 0.5792 - accuracy: 0.8175\n",
            "782/782 [==============================] - 1s 1ms/step - loss: 0.5422 - accuracy: 0.8406\n",
            "Test Accuracy: 0.8406000137329102\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}