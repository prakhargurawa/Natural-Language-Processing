{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ANLP_Lab_4_Prakhar_Gurawa.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZWnBK1AAel5"
      },
      "source": [
        "# ANLP Lab 4: Recurrent Neural Networks\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQlE8AfOB_kR"
      },
      "source": [
        "# Task 1\n",
        "\n",
        "The figure below shows an RNN with one input unit $x$, one logistic hidden unit $h$, and one linear output unit $y$. The RNN is unrolled in time for T = 0, 1, and 2. \n",
        "\n",
        "![Screenshot from 2020-11-09 14-30-23.png](data:image/png;base64,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)\n",
        "\n",
        "The network parameters are: \n",
        "\n",
        "$W_{xh} = 0.5,$\n",
        "\n",
        "$W_{hh} = −1.0,$\n",
        "\n",
        "$W_{hy} = −0.7,$\n",
        "\n",
        "$h_{bias} = -1.0$ and,\n",
        "\n",
        "$y_{bias} = 0.0.$\n",
        "\n",
        "If the input $x$ takes the values 9, 4, −2 at time steps 0, 1, 2 respectively, what is the value of the output $y$ at T = 2? Give your answer to at least two digits after the decimal point.\n",
        "\n",
        "Remember, \n",
        "\n",
        "$y_i = W_{hy}h_i + y_{bias}$\n",
        "\n",
        "$h_i = \\sigma(W_{xh}x_i + W_{hh}h_{i-1} + h_{bias})$\n",
        "\n",
        "$\\sigma(k)= \\frac{1}{1+\\exp(-k)}$\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10uvHueQMYyA"
      },
      "source": [
        "### Solution\r\n",
        "\r\n",
        "$z_0 = W_{xh}x_0+h_{bias} = 0.5 * 9 + (-1.0) = 3.5$\r\n",
        "\r\n",
        "$h_0 =  \\sigma(z_0) = 1/(1 + exp(-3.5))=0.9706$\r\n",
        "\r\n",
        "$y_0= W_{hy}h_0 + y_{bias}= -0.7 * 0.9706 + 0.0= -0.6794$\r\n",
        "\r\n",
        "\r\n",
        "$z_1 = W_{xh}x_1+W_{hh}h_0 + h_{bias} = 0.5*4 + -1.0*0.9706 + (-1.0) = 0.0294$\r\n",
        "\r\n",
        "$h_1= \\sigma(z_1) =  1/(1 + exp(-0.0294))=0.5073$\r\n",
        "\r\n",
        "$y_1= W_{hy}h_1 + y_{bias} = -0.7 * 0.5073 + 0.0 = -0.35511$\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "$z_2 = W_{xh}x_2+W_{hh}h_1 + h_{bias} = 0.5 * -2 + -1.0 *0.5073 + (-1.0) = -2.5073$\r\n",
        "\r\n",
        "$h_2= \\sigma(z_2) =  1/(1 + exp(2.4926))=0.0763$\r\n",
        "\r\n",
        "$y_2 = W_{hy}h_2 + y_{bias}= -0.7 * 0.0763 + 0.0 = -0.05341$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3gbX4jSChNo"
      },
      "source": [
        "#Task 2\n",
        "### A step-by-step implementation of an RNN with LSTM using Keras\n",
        "\n",
        "We will use the [Penn Tree Bank (PTB)](https://catalog.ldc.upenn.edu/LDC99T42) dataset as it is already split into train, validation and test datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yn55fOgbRXX7"
      },
      "source": [
        "# Importing libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense, Activation, Embedding, TimeDistributed, LSTM\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvBXGxj6CxoN"
      },
      "source": [
        "## Training Data and Preprocessing\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dTp1xo-AxnO"
      },
      "source": [
        "### Text preprocessing functions\n",
        "\n",
        "The following is some code to load the data, please examine it and refer to the [documentation for LabelEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v79f_uuiDAXd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d61c50a4-c742-4150-cb36-ff0fd53f291f"
      },
      "source": [
        "!wget www.fit.vutbr.cz/~imikolov/rnnlm/simple-examples.tgz\n",
        "!tar -zxf  simple-examples.tgz\n",
        "data_path = \"simple-examples/data/\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-03-06 19:01:50--  http://www.fit.vutbr.cz/~imikolov/rnnlm/simple-examples.tgz\n",
            "Resolving www.fit.vutbr.cz (www.fit.vutbr.cz)... 147.229.9.23, 2001:67c:1220:809::93e5:917\n",
            "Connecting to www.fit.vutbr.cz (www.fit.vutbr.cz)|147.229.9.23|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 34869662 (33M) [application/x-gtar]\n",
            "Saving to: ‘simple-examples.tgz’\n",
            "\n",
            "simple-examples.tgz 100%[===================>]  33.25M  18.6MB/s    in 1.8s    \n",
            "\n",
            "2021-03-06 19:01:52 (18.6 MB/s) - ‘simple-examples.tgz’ saved [34869662/34869662]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVIdRcZfe1tJ"
      },
      "source": [
        "def read_words(filename):\n",
        "    with open(filename, \"r\") as f: \n",
        "       return f.read().replace(\"\\n\", \"<eos>\").split()\n",
        "\n",
        "def load_data():\n",
        "    # get the data\n",
        "    train_words = read_words(data_path + \"ptb.train.txt\")\n",
        "    valid_words = read_words(data_path + \"ptb.valid.txt\")\n",
        "    test_words = read_words(data_path + \"ptb.test.txt\")\n",
        "\n",
        "    # build a word2idx vocabulary\n",
        "    le = LabelEncoder()\n",
        "    le.fit(train_words + valid_words + test_words)\n",
        "    train_data = le.transform(train_words)\n",
        "    valid_data = le.transform(valid_words)\n",
        "    test_data = le.transform(test_words)\n",
        "\n",
        "    return train_data, valid_data, test_data, le"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57o7pKka9VZV"
      },
      "source": [
        "To call this function, we can run:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6hgalqwDtnD"
      },
      "source": [
        "train_data, valid_data, test_data, encoder = load_data()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTG54mLNGyye"
      },
      "source": [
        "### Creating the Keras LSTM data generators\n",
        "\n",
        "![alt text](https://cdn-images-1.medium.com/max/800/1*XvUt5wDQA8D3C0wAuxAvbA.png)\n",
        "\n",
        "The training y data in our implementation is the input x words advanced one time step – in other words, at each time step the model is trying to predict the very next word in the sequence. \n",
        "\n",
        "When training neural networks, we generally feed data into them in small batches. Create a generator following these steps:\n",
        "\n",
        "\n",
        "Parameters to know:\n",
        "- *num_steps*: this is the number of words that we will feed into the time distributed input layer of the network. \n",
        "- *batch_size*: the size of the batch \n",
        "- *skip_steps* is the number of words we want to skip over between training samples within each batch\n",
        "- reset *current_idx* to zero so that the data consumption starts from the beginning of the data set again "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AWF9qgUAxb8"
      },
      "source": [
        "class KerasBatchGenerator(object):\n",
        "\n",
        "    def __init__(self, data, num_steps, batch_size, vocab_size, skip_step=5):\n",
        "        self.data = data\n",
        "        self.num_steps = num_steps\n",
        "        self.batch_size = batch_size\n",
        "        self.vocab_size = vocab_size\n",
        "        # this will track the progress of the batches sequentially through the\n",
        "        # data set - once the data reaches the end of the data set it will reset\n",
        "        # back to zero\n",
        "        self.current_idx = 0\n",
        "        # skip_step is the number of words which will be skipped before the next\n",
        "        # batch is skimmed from the data set\n",
        "        self.skip_step = skip_step\n",
        "        \n",
        "    def generate(self):\n",
        "      x = np.zeros((self.batch_size, self.num_steps))\n",
        "      y = np.zeros((self.batch_size, self.num_steps, self.vocab_size))\n",
        "      while True:\n",
        "          for i in range(self.batch_size):\n",
        "              if self.current_idx + self.num_steps >= len(self.data):\n",
        "                # reset the index back to the start of the data set\n",
        "                self.current_idx = 0\n",
        "              x[i, :] = self.data[self.current_idx:self.current_idx + self.num_steps]\n",
        "              temp_y = self.data[self.current_idx + 1:self.current_idx + self.num_steps + 1]\n",
        "              # convert all of temp_y into a one hot representation\n",
        "              y[i, :, :] = to_categorical(temp_y, num_classes=self.vocab_size)\n",
        "              self.current_idx += self.skip_step\n",
        "          yield x, y"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6-pUULs8ne0"
      },
      "source": [
        "Look at the initializer of the `KerasBatchGenerator` class.  Define the required hyperparameters of the model and instantialize the class for the training set and the validation set. Your train generator should return a batch of `batch_size` subseqences of length `num_steps` and as `y` the one-hot representation of the next word"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txYCyQsQ-mVH"
      },
      "source": [
        "num_steps = 10\n",
        "batch_size = 10\n",
        "hidden_size = 5\n",
        "num_epochs = 5\n",
        "vocab_size = len(encoder.classes_)\n",
        "\n",
        "train_data_generator = KerasBatchGenerator(train_data, num_steps, batch_size, vocab_size, skip_step=num_steps)\n",
        "valid_data_generator = KerasBatchGenerator(valid_data, num_steps, batch_size, vocab_size, skip_step=num_steps)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62bypYFMSqfO"
      },
      "source": [
        "## Creating the Keras LSTM structure\n",
        "Following the schema of the network above, add the various layers of the networks using `model.add()`. You network should consist of\n",
        "\n",
        "* An embedding layer\n",
        "* At least one LSTM layer\n",
        "* A [time-distributed](https://keras.io/api/layers/recurrent_layers/time_distributed/) layer\n",
        "* An output layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwmKZeMJ9-g7"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, hidden_size, input_length=num_steps))\n",
        "model.add(LSTM(hidden_size, return_sequences=True))\n",
        "model.add(LSTM(hidden_size, return_sequences=True))\n",
        "model.add(TimeDistributed(Dense(vocab_size)))\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9rzztOP-Fdu"
      },
      "source": [
        "### Compiling and running the Keras LSTM model\n",
        "\n",
        "The next step in Keras, once you’ve completed your model, is to run the compile command on the model. It looks like this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkeXA9_eHm6L"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jeSup4MZHrK4"
      },
      "source": [
        "checkpointer = ModelCheckpoint(filepath=data_path + 'model.hdf5', verbose=1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRKlD-0BHxOm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "229f192b-8fd3-409b-c3de-035f9ca4e714"
      },
      "source": [
        "model.fit_generator(train_data_generator.generate(), len(train_data)//(batch_size*num_steps), num_epochs,\n",
        "                        validation_data=valid_data_generator.generate(),\n",
        "                        validation_steps=len(valid_data)//(batch_size*num_steps), callbacks=[checkpointer])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "9295/9295 [==============================] - 249s 26ms/step - loss: 6.9642 - accuracy: 0.0514 - val_loss: 6.5443 - val_accuracy: 0.0559\n",
            "\n",
            "Epoch 00001: saving model to simple-examples/data/model.hdf5\n",
            "Epoch 2/5\n",
            "9295/9295 [==============================] - 243s 26ms/step - loss: 6.5228 - accuracy: 0.0611 - val_loss: 6.3540 - val_accuracy: 0.0866\n",
            "\n",
            "Epoch 00002: saving model to simple-examples/data/model.hdf5\n",
            "Epoch 3/5\n",
            "9295/9295 [==============================] - 246s 26ms/step - loss: 6.3415 - accuracy: 0.0942 - val_loss: 6.2307 - val_accuracy: 0.0986\n",
            "\n",
            "Epoch 00003: saving model to simple-examples/data/model.hdf5\n",
            "Epoch 4/5\n",
            "9295/9295 [==============================] - 248s 27ms/step - loss: 6.2134 - accuracy: 0.1071 - val_loss: 6.0754 - val_accuracy: 0.1276\n",
            "\n",
            "Epoch 00004: saving model to simple-examples/data/model.hdf5\n",
            "Epoch 5/5\n",
            "9295/9295 [==============================] - 245s 26ms/step - loss: 6.0506 - accuracy: 0.1313 - val_loss: 5.9558 - val_accuracy: 0.1382\n",
            "\n",
            "Epoch 00005: saving model to simple-examples/data/model.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1da87120d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMtrduXQR-L4"
      },
      "source": [
        "`fit_generator` is a Keras function that can extract training data automatically from a pre-supplied Python iterator/generator object and input it to the model. \n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRCh_hJKWeyC"
      },
      "source": [
        "# Task 3: text generation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1AtTf_jJK0-"
      },
      "source": [
        "## The Keras LSTM results\n",
        "\n",
        "In order to test the trained Keras LSTM model, one can compare the predicted word outputs against what the actual word sequences are in the training and test data set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Ov2vs4tJBH9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a674d53-32f6-4a87-9dcd-53ca3b7d6729"
      },
      "source": [
        "model = load_model(data_path + '/model.hdf5')\n",
        "reversed_dictionary = dict(zip(encoder.transform(encoder.classes_), encoder.classes_))\n",
        "example_training_generator = KerasBatchGenerator(train_data, num_steps, 1, vocab_size, skip_step=1)\n",
        "dummy_iters = 1\n",
        "\n",
        "print(\"Training data...\")\n",
        "for i in range(dummy_iters):\n",
        "    dummy = next(example_training_generator.generate())\n",
        "\n",
        "num_predict = 10\n",
        "true_print_out = \"Actual words: \"\n",
        "pred_print_out = \"Predicted words: \"\n",
        "\n",
        "for i in range(num_predict):\n",
        "    data = next(example_training_generator.generate())\n",
        "    prediction = model.predict(data[0])\n",
        "    predict_word = np.argmax(prediction[:, num_steps-1, :])\n",
        "    true_print_out += reversed_dictionary[train_data[num_steps + dummy_iters + i]] + \" \"\n",
        "    pred_print_out += reversed_dictionary[predict_word] + \" \""
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training data...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3rw6mDsvtJ1",
        "outputId": "d49fd932-947a-4b8f-ae62-626a3670a287"
      },
      "source": [
        "print(true_print_out)\r\n",
        "print(pred_print_out)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Actual words: kia memotec mlx nahb punts rake regatta rubens sim snack-food \n",
            "Predicted words: <eos> <eos> <eos> <eos> the <eos> <eos> <eos> <eos> <eos> \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7CLekkU9VEN"
      },
      "source": [
        "How the output can get improved? Maybe tuning the hyperparmeters to make your model learn more or add a dropout layer?\n",
        "\n",
        "#### Some ideas\n",
        "\n",
        "1. More training epochs\n",
        "2. Bigger hidden layer size\n",
        "3. Stack more layers\n",
        "4. Add a dropout layer to prevent overfitting\n",
        "5. Use pre-trained word embeddings\n",
        "6. Increase the seed sequence length\n",
        "7. Randomize index resetting to skip different words at different passes (requires re-designing batch generator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wg0wlEIxV9cD"
      },
      "source": [
        "## Further reading\n",
        "\n",
        "[The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)\n",
        "\n",
        "[Understanding LSTM Networks](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)\n",
        "\n",
        "[LSTM in Keras tutorial](https://adventuresinmachinelearning.com/keras-lstm-tutorial/)\n",
        "\n",
        "[RNNs in Tensorflow, a Practical Guide and Undocumented Features](http://www.wildml.com/2016/08/rnns-in-tensorflow-a-practical-guide-and-undocumented-features/)\n",
        "\n",
        "\n"
      ]
    }
  ]
}