{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ANLP_Lab_8_Prakhar.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZbunxcIfZgk"
      },
      "source": [
        "# Objectives\n",
        "* Learn to preprocess the data for Neural Machine Translation system\n",
        "* Learn to train NMT using encoder-decoder model\n",
        "* Learn to use the trained model to create inference\n",
        "* Reference: https://keras.io \n",
        "https://github.com/keras-team/keras/blob/master/examples/lstm_seq2seq.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u66-P69TOmS9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94d71205-de01-425c-e7e9-a999d3f4d114"
      },
      "source": [
        "import numpy as np\n",
        "import keras, tensorflow\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Dense"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shyumtBqeKVI"
      },
      "source": [
        "##**Section 1**\n",
        "\n",
        "---\n",
        "\n",
        "## **Data Preparation **"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhvOghq8OnW6"
      },
      "source": [
        "**Task 1**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "There are few datasets for langauge trasnaltion task are available from Tatoeba Project (http://www.manythings.org/anki/ ).\n",
        "\n",
        "*  Download preferred langauge pair\n",
        "*  Extract the file and upload it to colab\n",
        "*  Create a list of lines by splitting the text file at every occurance of '\\n'\n",
        "*  Print number of sentences\n",
        "*  Print 100th sentence in original script\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGJwxkrxTelg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "894abdec-8693-4e97-cc42-2d76398ee9af"
      },
      "source": [
        "!wget http://www.manythings.org/anki/nld-eng.zip\n",
        "!unzip nld-eng.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-15 19:46:04--  http://www.manythings.org/anki/nld-eng.zip\n",
            "Resolving www.manythings.org (www.manythings.org)... 104.21.55.222, 172.67.173.198, 2606:4700:3031::6815:37de, ...\n",
            "Connecting to www.manythings.org (www.manythings.org)|104.21.55.222|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1975354 (1.9M) [application/zip]\n",
            "Saving to: ‘nld-eng.zip.2’\n",
            "\n",
            "nld-eng.zip.2       100%[===================>]   1.88M  1.04MB/s    in 1.8s    \n",
            "\n",
            "2021-04-15 19:46:06 (1.04 MB/s) - ‘nld-eng.zip.2’ saved [1975354/1975354]\n",
            "\n",
            "Archive:  nld-eng.zip\n",
            "  inflating: _about.txt              \n",
            "  inflating: nld.txt                 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFRmNnlTOmi_"
      },
      "source": [
        "filename=\"nld.txt\"\n",
        "with open(filename , 'r') as tamil_file:\n",
        "  lines=tamil_file.read().split('\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtI54EeOjJLU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f84fd9b-fe61-4798-c29d-e8dbe1a28b84"
      },
      "source": [
        "print(len(lines))\n",
        "print(lines[100])\n",
        "#lines"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "28548\n",
            "I'm back.\tIk ben weer thuis.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RiTMo8UW83F"
      },
      "source": [
        "**Task 2**\n",
        "\n",
        "---\n",
        "\n",
        "* Split each line into input text and target text\n",
        "* Add '\\t' to denote begning of sentence and '\\n'  or '<eos\\>' to denote end of the sentence to the each target line.\n",
        "* Compute every set of character in the input text and target text\n",
        "* Print input characters and target characters as sorted list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDW2I1TrWtLc"
      },
      "source": [
        "input_texts = list()\n",
        "target_texts = list()\n",
        "input_characters = set()\n",
        "target_characters = set()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmQC0PyxXzR8"
      },
      "source": [
        "num_samples = 10000\n",
        "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
        "  input_text, target_text = line.split('\\t')\n",
        "  target_text = '\\t' + target_text + '\\n'\n",
        "  input_texts.append(input_text)\n",
        "  target_texts.append(target_text)\n",
        "  for char in input_text:\n",
        "    if char not in input_characters:\n",
        "      input_characters.add(char)\n",
        "  for char in target_text:\n",
        "    if char not in target_characters:\n",
        "      target_characters.add(char)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3-iYgr7XcBu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d7eb875-196b-4e46-ff87-3a67f363f1a8"
      },
      "source": [
        "input_characters = sorted(list(input_characters))\n",
        "target_characters = sorted(list(target_characters))\n",
        "num_encoder_tokens = len(input_characters)\n",
        "num_decoder_tokens = len(target_characters)\n",
        "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
        "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
        "\n",
        "print('Number of samples:', len(input_texts))\n",
        "print('Number of unique input tokens:', num_encoder_tokens)\n",
        "print('Number of unique output tokens:', num_decoder_tokens)\n",
        "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
        "print('Max sequence length for outputs:', max_decoder_seq_length)\n",
        "print(\"Input characters\",input_characters)\n",
        "print(\"Target characters\",target_characters)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Number of samples:', 10000)\n",
            "('Number of unique input tokens:', 74)\n",
            "('Number of unique output tokens:', 81)\n",
            "('Max sequence length for inputs:', 24)\n",
            "('Max sequence length for outputs:', 58)\n",
            "('Input characters', [' ', '!', '\"', '$', \"'\", ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'R', 'S', 'T', 'U', 'V', 'W', 'Y', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '\\x82', '\\xa9', '\\xac', '\\xc3', '\\xe2'])\n",
            "('Target characters', ['\\t', '\\n', ' ', '!', '\"', \"'\", ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'R', 'S', 'T', 'U', 'V', 'W', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '\\x82', '\\xa8', '\\xa9', '\\xaa', '\\xab', '\\xac', '\\xaf', '\\xb3', '\\xc3', '\\xe2'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIXRZ8AUZKVB"
      },
      "source": [
        "**Task 3**\n",
        "\n",
        "---\n",
        "\n",
        "*  Tokenize our characters by assigning each unique character to an integer value.\n",
        "*  Create one-hot encoding\n",
        "*  Create numeric data with one-hot encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXyzaZ-AZjvJ"
      },
      "source": [
        "input_token_index = dict([(char,i) for i, char in enumerate(input_characters)])\n",
        "target_token_index= dict([(char,i) for i, char in enumerate(target_characters)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AP5ZJ6irF6vl"
      },
      "source": [
        "input_token_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IUfXaToZ2Rg"
      },
      "source": [
        "The encoder_input_data will consist of  samples of the maximum sequence length (24) filled with the respective one-hot-encoded tokens (in this case a vector of length 74). The decoder_input_data and the decoder_target_data are both constructed in the same way as the input data for the encoder. We need to construct those two sequences because we're training our model through a process called teacher forcing, where the decoder learns to generate decoder_target_data[t+1...] given decoder_input_data[...t] while taking into account the input sequence via the encoder's internal state. Therefore we have to offset decoder_target_data by one timestep."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBY5c-6pZsry"
      },
      "source": [
        "encoder_input_data=np.zeros((len(input_texts),max_encoder_seq_length,num_encoder_tokens),dtype='float32')\n",
        "decoder_input_data=np.zeros((len(input_texts), max_decoder_seq_length, num_decoder_tokens),dtype='float32')\n",
        "decoder_target_data=np.zeros((len(input_texts), max_decoder_seq_length, num_decoder_tokens),dtype='float32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sx0TDwf0ZueF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff3fe78f-66d3-496a-afa0-2ed52eb6607f"
      },
      "source": [
        "print(encoder_input_data.shape)\n",
        "print(decoder_input_data.shape)\n",
        "print(decoder_target_data.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 24, 74)\n",
            "(10000, 58, 81)\n",
            "(10000, 58, 81)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8E3LkfJbYVF"
      },
      "source": [
        "for i, (input_text,target_text) in enumerate(zip(input_texts,target_texts)):\n",
        "  for t, char in enumerate(input_text):\n",
        "    encoder_input_data[i,t,input_token_index[char]]=1\n",
        "    \n",
        "  for t, char in enumerate(target_text):\n",
        "    decoder_input_data[i,t,target_token_index[char]]=1\n",
        "    if t>0:\n",
        "      decoder_target_data[i,t-1,target_token_index[char]]=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8bTOqHfeCHZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a1fa6ba-46df-46ec-8797-0b3c09985572"
      },
      "source": [
        "print(encoder_input_data[0][0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbGU3H0gecBd"
      },
      "source": [
        "## **Section 2**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "## **Building the Model **"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5vkd552e6ck"
      },
      "source": [
        "**Hyperparameters **"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lz-weK3JuXmy"
      },
      "source": [
        "** Use GPU/TPU to run the model **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5F3cPK2eE1Z"
      },
      "source": [
        "batch_size=64\n",
        "epochs= 2\n",
        "latent_dim =256 # latent dimensionality of the encoding space"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rq6r-IufHWr"
      },
      "source": [
        "encoder_inputs=Input(shape=(None,num_encoder_tokens))\n",
        "encoder_lstm= LSTM(latent_dim,return_state=True) #\n",
        "encoder_outputs,state_h,state_c= encoder_lstm(encoder_inputs)\n",
        "encoder_states= [state_h,state_c]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dL70cqDogeDh"
      },
      "source": [
        "decoder_inputs=Input(shape=(None,num_decoder_tokens))\n",
        "decoder_lstm=LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_output,_,_=decoder_lstm(decoder_inputs,initial_state=encoder_states)\n",
        "\n",
        "decoder_dense= Dense(num_decoder_tokens, activation='softmax')\n",
        "decoder_outputs=decoder_dense(decoder_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0Pun-T4hM6b"
      },
      "source": [
        "model= Model(inputs=[encoder_inputs,decoder_inputs],outputs=decoder_outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqwcU36sh4ld"
      },
      "source": [
        "model.compile(optimizer='rmsprop',loss='categorical_crossentropy')\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggo3qyIxh7M8"
      },
      "source": [
        "## ** Section 3 **\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "** Training Model **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPvWdhaBiBPL"
      },
      "source": [
        "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          validation_split=0.2)\n",
        "model.save('seq2seq_eng-nl.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-J_veVXaUiyQ"
      },
      "source": [
        "# Testing Machine Translation\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "* Use the compiled model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOVU0W56izum"
      },
      "source": [
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
        "model.load_weights('seq2seq_eng-nl.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M01ZBtVhUhhI"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmz0UQyFUQaN"
      },
      "source": [
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(\n",
        "  decoder_inputs, initial_state=decoder_states_inputs)\n",
        "decoder_states = [state_h, state_c]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "decoder_model = Model(\n",
        "  [decoder_inputs] + decoder_states_inputs,\n",
        "  [decoder_outputs] + decoder_states)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQXF1Si6VMKz"
      },
      "source": [
        "# reverse-lookup token index to turn sequences back to characters\n",
        "reverse_input_char_index = dict(\n",
        "  (i, char) for char, i in input_token_index.items())\n",
        "reverse_target_char_index = dict(\n",
        "  (i, char) for char, i in target_token_index.items())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7qik3jTVR_r"
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "  # encode the input sequence to get the internal state vectors.\n",
        "  states_value = encoder_model.predict(input_seq)\n",
        "  \n",
        "  # generate empty target sequence of length 1 with only the start character\n",
        "  target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "  target_seq[0, 0, target_token_index['\\t']] = 1.\n",
        "  \n",
        "  # output sequence loop\n",
        "  stop_condition = False\n",
        "  decoded_sentence = ''\n",
        "  while not stop_condition:\n",
        "    output_tokens, h, c = decoder_model.predict(\n",
        "      [target_seq] + states_value)\n",
        "    \n",
        "    # sample a token and add the corresponding character to the \n",
        "    # decoded sequence\n",
        "    sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "    sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "    decoded_sentence += sampled_char\n",
        "    \n",
        "    # check for the exit condition: either hitting max length\n",
        "    # or predicting the 'stop' character\n",
        "    if (sampled_char == '\\n' or \n",
        "        len(decoded_sentence) > max_decoder_seq_length):\n",
        "      stop_condition = True\n",
        "      \n",
        "    # update the target sequence (length 1).\n",
        "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "    target_seq[0, 0, sampled_token_index] = 1.\n",
        "    \n",
        "    # update states\n",
        "    states_value = [h, c]\n",
        "    \n",
        "  return decoded_sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iniHlKvQDbw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "outputId": "2d6e9d86-d6b6-4b3b-f32a-0fa06275ca93"
      },
      "source": [
        "for seq_index in range(10):\n",
        "  input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
        "  decoded_sentence = decode_sequence(input_seq)\n",
        "  print('-')\n",
        "  print('Input sentence:', input_texts[seq_index])\n",
        "  print('Decoded sentence:', decoded_sentence)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-\n",
            "('Input sentence:', 'Hi.')\n",
            "('Decoded sentence:', 'Hoi.\\n')\n",
            "-\n",
            "('Input sentence:', 'Run!')\n",
            "('Decoded sentence:', 'Gewrader ok niet in huister?\\n')\n",
            "-\n",
            "('Input sentence:', 'Who?')\n",
            "('Decoded sentence:', 'Wie?\\n')\n",
            "-\n",
            "('Input sentence:', 'Wow!')\n",
            "('Decoded sentence:', \"Wa's niet gek!\\n\")\n",
            "-\n",
            "('Input sentence:', 'Fire!')\n",
            "('Decoded sentence:', 'Vuur!\\n')\n",
            "-\n",
            "('Input sentence:', 'Fire!')\n",
            "('Decoded sentence:', 'Vuur!\\n')\n",
            "-\n",
            "('Input sentence:', 'Help!')\n",
            "('Decoded sentence:', 'Help!\\n')\n",
            "-\n",
            "('Input sentence:', 'Jump.')\n",
            "('Decoded sentence:', 'Spring.\\n')\n",
            "-\n",
            "('Input sentence:', 'Stop!')\n",
            "('Decoded sentence:', 'Halt!\\n')\n",
            "-\n",
            "('Input sentence:', 'Stop!')\n",
            "('Decoded sentence:', 'Halt!\\n')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBJ4SIpAQHP_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}